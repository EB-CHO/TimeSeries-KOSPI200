{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\82102\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>날짜</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>cny_krw</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>국고채</th>\n",
       "      <th>wti</th>\n",
       "      <th>brent</th>\n",
       "      <th>gold</th>\n",
       "      <th>vix</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>1738</td>\n",
       "      <td>278.10</td>\n",
       "      <td>629.47</td>\n",
       "      <td>20,636.92</td>\n",
       "      <td>18,355.26</td>\n",
       "      <td>3,222.17</td>\n",
       "      <td>1,133.02</td>\n",
       "      <td>164.63</td>\n",
       "      <td>10.4037</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>52.73</td>\n",
       "      <td>55.36</td>\n",
       "      <td>1,291.90</td>\n",
       "      <td>14.66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>1737</td>\n",
       "      <td>278.23</td>\n",
       "      <td>634.73</td>\n",
       "      <td>20,636.92</td>\n",
       "      <td>18,418.59</td>\n",
       "      <td>3,196.71</td>\n",
       "      <td>1,133.02</td>\n",
       "      <td>166.03</td>\n",
       "      <td>10.5386</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>52.73</td>\n",
       "      <td>55.36</td>\n",
       "      <td>1,291.90</td>\n",
       "      <td>14.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>1736</td>\n",
       "      <td>276.49</td>\n",
       "      <td>635.99</td>\n",
       "      <td>20,523.28</td>\n",
       "      <td>18,432.20</td>\n",
       "      <td>3,170.69</td>\n",
       "      <td>1,142.64</td>\n",
       "      <td>166.05</td>\n",
       "      <td>10.5056</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>52.33</td>\n",
       "      <td>54.89</td>\n",
       "      <td>1,294.10</td>\n",
       "      <td>14.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>1735</td>\n",
       "      <td>277.76</td>\n",
       "      <td>635.80</td>\n",
       "      <td>20,404.49</td>\n",
       "      <td>18,430.49</td>\n",
       "      <td>3,172.10</td>\n",
       "      <td>1,143.69</td>\n",
       "      <td>165.37</td>\n",
       "      <td>10.4108</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>50.62</td>\n",
       "      <td>52.93</td>\n",
       "      <td>1,283.40</td>\n",
       "      <td>14.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>1734</td>\n",
       "      <td>280.05</td>\n",
       "      <td>634.96</td>\n",
       "      <td>20,578.71</td>\n",
       "      <td>18,620.75</td>\n",
       "      <td>3,173.15</td>\n",
       "      <td>1,138.12</td>\n",
       "      <td>164.77</td>\n",
       "      <td>10.4008</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>50.27</td>\n",
       "      <td>52.99</td>\n",
       "      <td>1,283.80</td>\n",
       "      <td>14.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1          날짜  Unnamed: 0  kospi200  kosdaq        dow  \\\n",
       "0             0  2017-04-17        1738    278.10  629.47  20,636.92   \n",
       "1             1  2017-04-18        1737    278.23  634.73  20,636.92   \n",
       "2             2  2017-04-19        1736    276.49  635.99  20,523.28   \n",
       "3             3  2017-04-20        1735    277.76  635.80  20,404.49   \n",
       "4             4  2017-04-21        1734    280.05  634.96  20,578.71   \n",
       "\n",
       "      nikkei      ssec   usd_krw  cny_krw  jpy_krw   콜금리    국고채    wti  brent  \\\n",
       "0  18,355.26  3,222.17  1,133.02   164.63  10.4037  1.23  3.611  52.73  55.36   \n",
       "1  18,418.59  3,196.71  1,133.02   166.03  10.5386  1.23  3.611  52.73  55.36   \n",
       "2  18,432.20  3,170.69  1,142.64   166.05  10.5056  1.23  3.611  52.33  54.89   \n",
       "3  18,430.49  3,172.10  1,143.69   165.37  10.4108  1.24  3.611  50.62  52.93   \n",
       "4  18,620.75  3,173.15  1,138.12   164.77  10.4008  1.24  3.611  50.27  52.99   \n",
       "\n",
       "       gold    vix  Target  \n",
       "0  1,291.90  14.66       1  \n",
       "1  1,291.90  14.66       0  \n",
       "2  1,294.10  14.42       1  \n",
       "3  1,283.40  14.93       1  \n",
       "4  1,283.80  14.15       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('GRU-data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>brent</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>278.10</td>\n",
       "      <td>629.47</td>\n",
       "      <td>20,636.92</td>\n",
       "      <td>18,355.26</td>\n",
       "      <td>3,222.17</td>\n",
       "      <td>1.23</td>\n",
       "      <td>55.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>278.23</td>\n",
       "      <td>634.73</td>\n",
       "      <td>20,636.92</td>\n",
       "      <td>18,418.59</td>\n",
       "      <td>3,196.71</td>\n",
       "      <td>1.23</td>\n",
       "      <td>55.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>276.49</td>\n",
       "      <td>635.99</td>\n",
       "      <td>20,523.28</td>\n",
       "      <td>18,432.20</td>\n",
       "      <td>3,170.69</td>\n",
       "      <td>1.23</td>\n",
       "      <td>54.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>277.76</td>\n",
       "      <td>635.80</td>\n",
       "      <td>20,404.49</td>\n",
       "      <td>18,430.49</td>\n",
       "      <td>3,172.10</td>\n",
       "      <td>1.24</td>\n",
       "      <td>52.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>280.05</td>\n",
       "      <td>634.96</td>\n",
       "      <td>20,578.71</td>\n",
       "      <td>18,620.75</td>\n",
       "      <td>3,173.15</td>\n",
       "      <td>1.24</td>\n",
       "      <td>52.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜  kospi200  kosdaq        dow     nikkei      ssec   콜금리  brent  \\\n",
       "0  2017-04-17    278.10  629.47  20,636.92  18,355.26  3,222.17  1.23  55.36   \n",
       "1  2017-04-18    278.23  634.73  20,636.92  18,418.59  3,196.71  1.23  55.36   \n",
       "2  2017-04-19    276.49  635.99  20,523.28  18,432.20  3,170.69  1.23  54.89   \n",
       "3  2017-04-20    277.76  635.80  20,404.49  18,430.49  3,172.10  1.24  52.93   \n",
       "4  2017-04-21    280.05  634.96  20,578.71  18,620.75  3,173.15  1.24  52.99   \n",
       "\n",
       "   Target  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fi=df.drop(['Unnamed: 0.1','Unnamed: 0','usd_krw', 'cny_krw','gold','wti','jpy_krw','vix', '국고채'], axis=1)\n",
    "df_fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>brent</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>2024-05-14</td>\n",
       "      <td>371.04</td>\n",
       "      <td>862.22</td>\n",
       "      <td>39,431.64</td>\n",
       "      <td>38,314.50</td>\n",
       "      <td>3,146.29</td>\n",
       "      <td>4.917388</td>\n",
       "      <td>83.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>2024-05-13</td>\n",
       "      <td>370.98</td>\n",
       "      <td>854.43</td>\n",
       "      <td>39,431.64</td>\n",
       "      <td>38,179.46</td>\n",
       "      <td>3,148.17</td>\n",
       "      <td>4.910239</td>\n",
       "      <td>83.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>371.08</td>\n",
       "      <td>864.16</td>\n",
       "      <td>39,387.76</td>\n",
       "      <td>38,257.00</td>\n",
       "      <td>3,155.65</td>\n",
       "      <td>4.888839</td>\n",
       "      <td>83.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>368.84</td>\n",
       "      <td>870.15</td>\n",
       "      <td>39,055.73</td>\n",
       "      <td>38,070.50</td>\n",
       "      <td>3,155.43</td>\n",
       "      <td>4.881722</td>\n",
       "      <td>83.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>374.09</td>\n",
       "      <td>872.47</td>\n",
       "      <td>38,883.94</td>\n",
       "      <td>38,202.37</td>\n",
       "      <td>3,128.48</td>\n",
       "      <td>4.874613</td>\n",
       "      <td>82.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              날짜  kospi200  kosdaq        dow     nikkei      ssec       콜금리  \\\n",
       "1738  2024-05-14    371.04  862.22  39,431.64  38,314.50  3,146.29  4.917388   \n",
       "1737  2024-05-13    370.98  854.43  39,431.64  38,179.46  3,148.17  4.910239   \n",
       "1736  2024-05-10    371.08  864.16  39,387.76  38,257.00  3,155.65  4.888839   \n",
       "1735  2024-05-09    368.84  870.15  39,055.73  38,070.50  3,155.43  4.881722   \n",
       "1734  2024-05-08    374.09  872.47  38,883.94  38,202.37  3,128.48  4.874613   \n",
       "\n",
       "      brent  Target  \n",
       "1738  83.36       0  \n",
       "1737  83.36       1  \n",
       "1736  83.88       0  \n",
       "1735  83.58       1  \n",
       "1734  82.99       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 역순으로 정렬하여 전체 데이터의 70% 학습, 30% 테스트에 사용\n",
    "df_fi = df_fi[::-1]\n",
    "df_fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쉼표 제거 및 숫자 형식으로 변환, 날짜 열은 제외\n",
    "for column in df.columns:\n",
    "    if column != '날짜':\n",
    "        df[column] = df[column].apply(lambda x: str(x).replace(',', '') if isinstance(x, str) else x)\n",
    "        df[column] = df[column].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처와 타겟을 분리합니다\n",
    "features = df.drop(['Target', '날짜'], axis=1)\n",
    "target = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU 입력 형식으로 변환 (samples, time steps, features)\n",
    "time_steps = 5  # 이전 5일의 데이터를 사용하여 예측\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(time_steps, len(scaled_features)):\n",
    "    X.append(scaled_features[i-time_steps:i])\n",
    "    y.append(target.values[i])\n",
    "\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7  # 훈련 세트 비율\n",
    "split_index = int(split_ratio * len(X))\n",
    "\n",
    "X_train, y_train = X[:split_index], y[:split_index]\n",
    "X_test, y_test = X[split_index:], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\82102\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\82102\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(units=20))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\82102\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\82102\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "31/31 [==============================] - 4s 30ms/step - loss: 0.6905 - accuracy: 0.5474 - val_loss: 0.7006 - val_accuracy: 0.4856\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.5320 - val_loss: 0.7143 - val_accuracy: 0.4856\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5485 - val_loss: 0.6976 - val_accuracy: 0.4856\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5588 - val_loss: 0.6920 - val_accuracy: 0.5802\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5485 - val_loss: 0.6920 - val_accuracy: 0.5514\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6864 - accuracy: 0.5330 - val_loss: 0.6916 - val_accuracy: 0.5144\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6851 - accuracy: 0.5649 - val_loss: 0.6996 - val_accuracy: 0.4815\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6837 - accuracy: 0.5464 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.5763 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.5608 - val_loss: 0.6913 - val_accuracy: 0.5103\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5711 - val_loss: 0.6911 - val_accuracy: 0.5432\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5454 - val_loss: 0.6926 - val_accuracy: 0.5062\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5567 - val_loss: 0.6919 - val_accuracy: 0.5473\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.5567 - val_loss: 0.6967 - val_accuracy: 0.5144\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5464 - val_loss: 0.6916 - val_accuracy: 0.5432\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5454 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6829 - accuracy: 0.5505 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.5598 - val_loss: 0.6935 - val_accuracy: 0.5144\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6861 - accuracy: 0.5485 - val_loss: 0.6949 - val_accuracy: 0.4897\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5608 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5495 - val_loss: 0.6915 - val_accuracy: 0.5226\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6806 - accuracy: 0.5598 - val_loss: 0.6941 - val_accuracy: 0.5144\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5515 - val_loss: 0.6915 - val_accuracy: 0.5391\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.5598 - val_loss: 0.6944 - val_accuracy: 0.5144\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.5701 - val_loss: 0.6936 - val_accuracy: 0.5144\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5474 - val_loss: 0.6919 - val_accuracy: 0.5350\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.5557 - val_loss: 0.6963 - val_accuracy: 0.5144\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.5546 - val_loss: 0.6941 - val_accuracy: 0.5144\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.5784 - val_loss: 0.7095 - val_accuracy: 0.5144\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5557 - val_loss: 0.6919 - val_accuracy: 0.5267\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.5433 - val_loss: 0.6997 - val_accuracy: 0.5144\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6810 - accuracy: 0.5608 - val_loss: 0.6978 - val_accuracy: 0.5144\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.5412 - val_loss: 0.7072 - val_accuracy: 0.5144\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6831 - accuracy: 0.5619 - val_loss: 0.7169 - val_accuracy: 0.5144\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.5515 - val_loss: 0.6923 - val_accuracy: 0.5391\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.5474 - val_loss: 0.7102 - val_accuracy: 0.5144\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.5608 - val_loss: 0.7030 - val_accuracy: 0.5144\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.5371 - val_loss: 0.6922 - val_accuracy: 0.5267\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.5412 - val_loss: 0.6945 - val_accuracy: 0.5144\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5536 - val_loss: 0.7135 - val_accuracy: 0.5144\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.5670 - val_loss: 0.6964 - val_accuracy: 0.5144\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6837 - accuracy: 0.5608 - val_loss: 0.7018 - val_accuracy: 0.5144\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6804 - accuracy: 0.5629 - val_loss: 0.7035 - val_accuracy: 0.5144\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.5701 - val_loss: 0.7007 - val_accuracy: 0.5144\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5495 - val_loss: 0.6955 - val_accuracy: 0.5021\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.5371 - val_loss: 0.7005 - val_accuracy: 0.5144\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5629 - val_loss: 0.6971 - val_accuracy: 0.5144\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5567 - val_loss: 0.7153 - val_accuracy: 0.5144\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5588 - val_loss: 0.6980 - val_accuracy: 0.5144\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6808 - accuracy: 0.5567 - val_loss: 0.7097 - val_accuracy: 0.5144\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6800 - accuracy: 0.5732 - val_loss: 0.7045 - val_accuracy: 0.5144\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6797 - accuracy: 0.5505 - val_loss: 0.7048 - val_accuracy: 0.5144\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.5485 - val_loss: 0.6983 - val_accuracy: 0.5144\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5474 - val_loss: 0.7183 - val_accuracy: 0.5144\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6781 - accuracy: 0.5711 - val_loss: 0.7045 - val_accuracy: 0.5144\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6796 - accuracy: 0.5660 - val_loss: 0.7233 - val_accuracy: 0.5144\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.5660 - val_loss: 0.7156 - val_accuracy: 0.5144\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5732 - val_loss: 0.7214 - val_accuracy: 0.5144\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5701 - val_loss: 0.7071 - val_accuracy: 0.5144\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6780 - accuracy: 0.5763 - val_loss: 0.7226 - val_accuracy: 0.5144\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6790 - accuracy: 0.5701 - val_loss: 0.7086 - val_accuracy: 0.5144\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6805 - accuracy: 0.5515 - val_loss: 0.7148 - val_accuracy: 0.5144\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6794 - accuracy: 0.5649 - val_loss: 0.7161 - val_accuracy: 0.5144\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.5454 - val_loss: 0.7050 - val_accuracy: 0.5144\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5619 - val_loss: 0.7103 - val_accuracy: 0.5144\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5691 - val_loss: 0.7103 - val_accuracy: 0.5144\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.5670 - val_loss: 0.7103 - val_accuracy: 0.5144\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6817 - accuracy: 0.5588 - val_loss: 0.7149 - val_accuracy: 0.5144\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5701 - val_loss: 0.7140 - val_accuracy: 0.5144\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.5598 - val_loss: 0.7126 - val_accuracy: 0.5144\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5629 - val_loss: 0.7005 - val_accuracy: 0.5144\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5784 - val_loss: 0.7063 - val_accuracy: 0.5144\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6804 - accuracy: 0.5660 - val_loss: 0.7212 - val_accuracy: 0.5144\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.5845 - val_loss: 0.7107 - val_accuracy: 0.5144\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5577 - val_loss: 0.7249 - val_accuracy: 0.5144\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6791 - accuracy: 0.5722 - val_loss: 0.7139 - val_accuracy: 0.5144\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6797 - accuracy: 0.5588 - val_loss: 0.7137 - val_accuracy: 0.5144\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6781 - accuracy: 0.5722 - val_loss: 0.7202 - val_accuracy: 0.5144\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6788 - accuracy: 0.5722 - val_loss: 0.7050 - val_accuracy: 0.5144\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.5649 - val_loss: 0.7225 - val_accuracy: 0.5144\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6751 - accuracy: 0.5763 - val_loss: 0.7153 - val_accuracy: 0.5144\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6781 - accuracy: 0.5588 - val_loss: 0.7082 - val_accuracy: 0.5144\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5649 - val_loss: 0.7098 - val_accuracy: 0.5144\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6827 - accuracy: 0.5670 - val_loss: 0.7137 - val_accuracy: 0.5144\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6776 - accuracy: 0.5722 - val_loss: 0.7061 - val_accuracy: 0.5144\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5794 - val_loss: 0.7248 - val_accuracy: 0.5144\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.5649 - val_loss: 0.7126 - val_accuracy: 0.5144\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.5649 - val_loss: 0.7012 - val_accuracy: 0.5144\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5732 - val_loss: 0.7150 - val_accuracy: 0.5144\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5701 - val_loss: 0.7099 - val_accuracy: 0.5144\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6766 - accuracy: 0.5629 - val_loss: 0.7120 - val_accuracy: 0.5144\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.5691 - val_loss: 0.7104 - val_accuracy: 0.5144\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.5814 - val_loss: 0.7230 - val_accuracy: 0.5144\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.5701 - val_loss: 0.7099 - val_accuracy: 0.5144\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5732 - val_loss: 0.7363 - val_accuracy: 0.5144\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.5784 - val_loss: 0.7091 - val_accuracy: 0.5144\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6756 - accuracy: 0.5742 - val_loss: 0.7297 - val_accuracy: 0.5144\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6796 - accuracy: 0.5629 - val_loss: 0.7167 - val_accuracy: 0.5144\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6781 - accuracy: 0.5515 - val_loss: 0.7149 - val_accuracy: 0.5144\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6759 - accuracy: 0.5825 - val_loss: 0.7262 - val_accuracy: 0.5144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d4cc002b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)  # 이진 분류 문제이므로 0.5를 기준으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.508637236084453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>날짜</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>cny_krw</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>국고채</th>\n",
       "      <th>wti</th>\n",
       "      <th>brent</th>\n",
       "      <th>gold</th>\n",
       "      <th>vix</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>278.10</td>\n",
       "      <td>-75.076887</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2009.974391</td>\n",
       "      <td>-622.059252</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.758489</td>\n",
       "      <td>-0.509532</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>278.23</td>\n",
       "      <td>-75.704247</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2016.909279</td>\n",
       "      <td>-617.144046</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.943521</td>\n",
       "      <td>-0.516138</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>276.49</td>\n",
       "      <td>-75.854527</td>\n",
       "      <td>3597.730984</td>\n",
       "      <td>-2018.399629</td>\n",
       "      <td>-612.120729</td>\n",
       "      <td>92.633825</td>\n",
       "      <td>-21.946164</td>\n",
       "      <td>-0.514522</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.579164</td>\n",
       "      <td>-4.174933</td>\n",
       "      <td>74.850744</td>\n",
       "      <td>0.353896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>277.76</td>\n",
       "      <td>-75.831866</td>\n",
       "      <td>3576.907097</td>\n",
       "      <td>-2018.212377</td>\n",
       "      <td>-612.392938</td>\n",
       "      <td>92.718948</td>\n",
       "      <td>-21.856291</td>\n",
       "      <td>-0.509879</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.200789</td>\n",
       "      <td>-4.025856</td>\n",
       "      <td>74.231856</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>280.05</td>\n",
       "      <td>-75.731679</td>\n",
       "      <td>3607.447863</td>\n",
       "      <td>-2039.046608</td>\n",
       "      <td>-612.595646</td>\n",
       "      <td>92.267388</td>\n",
       "      <td>-21.776992</td>\n",
       "      <td>-0.509390</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.123343</td>\n",
       "      <td>-4.030419</td>\n",
       "      <td>74.254992</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1          날짜  Unnamed: 0  kospi200     kosdaq          dow  \\\n",
       "0           0.0  2017-04-17      1738.0    278.10 -75.076887  3617.652076   \n",
       "1           1.0  2017-04-18      1737.0    278.23 -75.704247  3617.652076   \n",
       "2           2.0  2017-04-19      1736.0    276.49 -75.854527  3597.730984   \n",
       "3           3.0  2017-04-20      1735.0    277.76 -75.831866  3576.907097   \n",
       "4           4.0  2017-04-21      1734.0    280.05 -75.731679  3607.447863   \n",
       "\n",
       "        nikkei        ssec    usd_krw    cny_krw   jpy_krw   콜금리    국고채  \\\n",
       "0 -2009.974391 -622.059252  91.853931 -21.758489 -0.509532  1.23  3.611   \n",
       "1 -2016.909279 -617.144046  91.853931 -21.943521 -0.516138  1.23  3.611   \n",
       "2 -2018.399629 -612.120729  92.633825 -21.946164 -0.514522  1.23  3.611   \n",
       "3 -2018.212377 -612.392938  92.718948 -21.856291 -0.509879  1.24  3.611   \n",
       "4 -2039.046608 -612.595646  92.267388 -21.776992 -0.509390  1.24  3.611   \n",
       "\n",
       "         wti     brent       gold       vix  Target  \n",
       "0  11.667673 -4.210682  74.723496  0.359786     1.0  \n",
       "1  11.667673 -4.210682  74.723496  0.359786     0.0  \n",
       "2  11.579164 -4.174933  74.850744  0.353896     1.0  \n",
       "3  11.200789 -4.025856  74.231856  0.366412     1.0  \n",
       "4  11.123343 -4.030419  74.254992  0.347269     1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피쳐 중요도 값을 딕셔너리 형태로 정의 (이미 제공된 값 사용)\n",
    "feature_importance = {\n",
    "   'wti': 0.221272,\n",
    "    'dow': 0.175300,\n",
    "    'usd_krw': 0.081070,\n",
    "    'gold': 0.057840,\n",
    "    'vix': 0.024542,\n",
    "    'jpy_krw': -0.048976,\n",
    "    'brent': -0.076060,\n",
    "    'nikkei': -0.109504,\n",
    "    'kosdaq': -0.119270,\n",
    "    'cny_krw': -0.132166,\n",
    "    'ssec': -0.193056\n",
    "}\n",
    "\n",
    "\n",
    "# 피쳐 중요도 값을 배열 형태로 정의\n",
    "feature_importance_arr = np.array(list(feature_importance.values()))\n",
    "\n",
    "# 피쳐 가중치 적용\n",
    "for feature, importance in feature_importance.items():\n",
    "    if feature in df.columns:\n",
    "        df[feature] *= importance\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>cny_krw</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>국고채</th>\n",
       "      <th>wti</th>\n",
       "      <th>brent</th>\n",
       "      <th>gold</th>\n",
       "      <th>vix</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>278.10</td>\n",
       "      <td>-75.076887</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2009.974391</td>\n",
       "      <td>-622.059252</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.758489</td>\n",
       "      <td>-0.509532</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>278.23</td>\n",
       "      <td>-75.704247</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2016.909279</td>\n",
       "      <td>-617.144046</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.943521</td>\n",
       "      <td>-0.516138</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>1736.0</td>\n",
       "      <td>276.49</td>\n",
       "      <td>-75.854527</td>\n",
       "      <td>3597.730984</td>\n",
       "      <td>-2018.399629</td>\n",
       "      <td>-612.120729</td>\n",
       "      <td>92.633825</td>\n",
       "      <td>-21.946164</td>\n",
       "      <td>-0.514522</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.579164</td>\n",
       "      <td>-4.174933</td>\n",
       "      <td>74.850744</td>\n",
       "      <td>0.353896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>277.76</td>\n",
       "      <td>-75.831866</td>\n",
       "      <td>3576.907097</td>\n",
       "      <td>-2018.212377</td>\n",
       "      <td>-612.392938</td>\n",
       "      <td>92.718948</td>\n",
       "      <td>-21.856291</td>\n",
       "      <td>-0.509879</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.200789</td>\n",
       "      <td>-4.025856</td>\n",
       "      <td>74.231856</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>280.05</td>\n",
       "      <td>-75.731679</td>\n",
       "      <td>3607.447863</td>\n",
       "      <td>-2039.046608</td>\n",
       "      <td>-612.595646</td>\n",
       "      <td>92.267388</td>\n",
       "      <td>-21.776992</td>\n",
       "      <td>-0.509390</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.123343</td>\n",
       "      <td>-4.030419</td>\n",
       "      <td>74.254992</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜  Unnamed: 0  kospi200     kosdaq          dow       nikkei  \\\n",
       "0  2017-04-17      1738.0    278.10 -75.076887  3617.652076 -2009.974391   \n",
       "1  2017-04-18      1737.0    278.23 -75.704247  3617.652076 -2016.909279   \n",
       "2  2017-04-19      1736.0    276.49 -75.854527  3597.730984 -2018.399629   \n",
       "3  2017-04-20      1735.0    277.76 -75.831866  3576.907097 -2018.212377   \n",
       "4  2017-04-21      1734.0    280.05 -75.731679  3607.447863 -2039.046608   \n",
       "\n",
       "         ssec    usd_krw    cny_krw   jpy_krw   콜금리    국고채        wti  \\\n",
       "0 -622.059252  91.853931 -21.758489 -0.509532  1.23  3.611  11.667673   \n",
       "1 -617.144046  91.853931 -21.943521 -0.516138  1.23  3.611  11.667673   \n",
       "2 -612.120729  92.633825 -21.946164 -0.514522  1.23  3.611  11.579164   \n",
       "3 -612.392938  92.718948 -21.856291 -0.509879  1.24  3.611  11.200789   \n",
       "4 -612.595646  92.267388 -21.776992 -0.509390  1.24  3.611  11.123343   \n",
       "\n",
       "      brent       gold       vix  Target  \n",
       "0 -4.210682  74.723496  0.359786     1.0  \n",
       "1 -4.210682  74.723496  0.359786     0.0  \n",
       "2 -4.174933  74.850744  0.353896     1.0  \n",
       "3 -4.025856  74.231856  0.366412     1.0  \n",
       "4 -4.030419  74.254992  0.347269     1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(['Unnamed: 0.1'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>cny_krw</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>국고채</th>\n",
       "      <th>wti</th>\n",
       "      <th>brent</th>\n",
       "      <th>gold</th>\n",
       "      <th>vix</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>278.10</td>\n",
       "      <td>-75.076887</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2009.974391</td>\n",
       "      <td>-622.059252</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.758489</td>\n",
       "      <td>-0.509532</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>278.23</td>\n",
       "      <td>-75.704247</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2016.909279</td>\n",
       "      <td>-617.144046</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.943521</td>\n",
       "      <td>-0.516138</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>276.49</td>\n",
       "      <td>-75.854527</td>\n",
       "      <td>3597.730984</td>\n",
       "      <td>-2018.399629</td>\n",
       "      <td>-612.120729</td>\n",
       "      <td>92.633825</td>\n",
       "      <td>-21.946164</td>\n",
       "      <td>-0.514522</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.579164</td>\n",
       "      <td>-4.174933</td>\n",
       "      <td>74.850744</td>\n",
       "      <td>0.353896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>277.76</td>\n",
       "      <td>-75.831866</td>\n",
       "      <td>3576.907097</td>\n",
       "      <td>-2018.212377</td>\n",
       "      <td>-612.392938</td>\n",
       "      <td>92.718948</td>\n",
       "      <td>-21.856291</td>\n",
       "      <td>-0.509879</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.200789</td>\n",
       "      <td>-4.025856</td>\n",
       "      <td>74.231856</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>280.05</td>\n",
       "      <td>-75.731679</td>\n",
       "      <td>3607.447863</td>\n",
       "      <td>-2039.046608</td>\n",
       "      <td>-612.595646</td>\n",
       "      <td>92.267388</td>\n",
       "      <td>-21.776992</td>\n",
       "      <td>-0.509390</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.611</td>\n",
       "      <td>11.123343</td>\n",
       "      <td>-4.030419</td>\n",
       "      <td>74.254992</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜  kospi200     kosdaq          dow       nikkei        ssec  \\\n",
       "0  2017-04-17    278.10 -75.076887  3617.652076 -2009.974391 -622.059252   \n",
       "1  2017-04-18    278.23 -75.704247  3617.652076 -2016.909279 -617.144046   \n",
       "2  2017-04-19    276.49 -75.854527  3597.730984 -2018.399629 -612.120729   \n",
       "3  2017-04-20    277.76 -75.831866  3576.907097 -2018.212377 -612.392938   \n",
       "4  2017-04-21    280.05 -75.731679  3607.447863 -2039.046608 -612.595646   \n",
       "\n",
       "     usd_krw    cny_krw   jpy_krw   콜금리    국고채        wti     brent  \\\n",
       "0  91.853931 -21.758489 -0.509532  1.23  3.611  11.667673 -4.210682   \n",
       "1  91.853931 -21.943521 -0.516138  1.23  3.611  11.667673 -4.210682   \n",
       "2  92.633825 -21.946164 -0.514522  1.23  3.611  11.579164 -4.174933   \n",
       "3  92.718948 -21.856291 -0.509879  1.24  3.611  11.200789 -4.025856   \n",
       "4  92.267388 -21.776992 -0.509390  1.24  3.611  11.123343 -4.030419   \n",
       "\n",
       "        gold       vix  Target  \n",
       "0  74.723496  0.359786     1.0  \n",
       "1  74.723496  0.359786     0.0  \n",
       "2  74.850744  0.353896     1.0  \n",
       "3  74.231856  0.366412     1.0  \n",
       "4  74.254992  0.347269     1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>kospi200</th>\n",
       "      <th>kosdaq</th>\n",
       "      <th>dow</th>\n",
       "      <th>nikkei</th>\n",
       "      <th>ssec</th>\n",
       "      <th>usd_krw</th>\n",
       "      <th>cny_krw</th>\n",
       "      <th>jpy_krw</th>\n",
       "      <th>콜금리</th>\n",
       "      <th>wti</th>\n",
       "      <th>brent</th>\n",
       "      <th>gold</th>\n",
       "      <th>vix</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>278.10</td>\n",
       "      <td>-75.076887</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2009.974391</td>\n",
       "      <td>-622.059252</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.758489</td>\n",
       "      <td>-0.509532</td>\n",
       "      <td>1.23</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>278.23</td>\n",
       "      <td>-75.704247</td>\n",
       "      <td>3617.652076</td>\n",
       "      <td>-2016.909279</td>\n",
       "      <td>-617.144046</td>\n",
       "      <td>91.853931</td>\n",
       "      <td>-21.943521</td>\n",
       "      <td>-0.516138</td>\n",
       "      <td>1.23</td>\n",
       "      <td>11.667673</td>\n",
       "      <td>-4.210682</td>\n",
       "      <td>74.723496</td>\n",
       "      <td>0.359786</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>276.49</td>\n",
       "      <td>-75.854527</td>\n",
       "      <td>3597.730984</td>\n",
       "      <td>-2018.399629</td>\n",
       "      <td>-612.120729</td>\n",
       "      <td>92.633825</td>\n",
       "      <td>-21.946164</td>\n",
       "      <td>-0.514522</td>\n",
       "      <td>1.23</td>\n",
       "      <td>11.579164</td>\n",
       "      <td>-4.174933</td>\n",
       "      <td>74.850744</td>\n",
       "      <td>0.353896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>277.76</td>\n",
       "      <td>-75.831866</td>\n",
       "      <td>3576.907097</td>\n",
       "      <td>-2018.212377</td>\n",
       "      <td>-612.392938</td>\n",
       "      <td>92.718948</td>\n",
       "      <td>-21.856291</td>\n",
       "      <td>-0.509879</td>\n",
       "      <td>1.24</td>\n",
       "      <td>11.200789</td>\n",
       "      <td>-4.025856</td>\n",
       "      <td>74.231856</td>\n",
       "      <td>0.366412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>280.05</td>\n",
       "      <td>-75.731679</td>\n",
       "      <td>3607.447863</td>\n",
       "      <td>-2039.046608</td>\n",
       "      <td>-612.595646</td>\n",
       "      <td>92.267388</td>\n",
       "      <td>-21.776992</td>\n",
       "      <td>-0.509390</td>\n",
       "      <td>1.24</td>\n",
       "      <td>11.123343</td>\n",
       "      <td>-4.030419</td>\n",
       "      <td>74.254992</td>\n",
       "      <td>0.347269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           날짜  kospi200     kosdaq          dow       nikkei        ssec  \\\n",
       "0  2017-04-17    278.10 -75.076887  3617.652076 -2009.974391 -622.059252   \n",
       "1  2017-04-18    278.23 -75.704247  3617.652076 -2016.909279 -617.144046   \n",
       "2  2017-04-19    276.49 -75.854527  3597.730984 -2018.399629 -612.120729   \n",
       "3  2017-04-20    277.76 -75.831866  3576.907097 -2018.212377 -612.392938   \n",
       "4  2017-04-21    280.05 -75.731679  3607.447863 -2039.046608 -612.595646   \n",
       "\n",
       "     usd_krw    cny_krw   jpy_krw   콜금리        wti     brent       gold  \\\n",
       "0  91.853931 -21.758489 -0.509532  1.23  11.667673 -4.210682  74.723496   \n",
       "1  91.853931 -21.943521 -0.516138  1.23  11.667673 -4.210682  74.723496   \n",
       "2  92.633825 -21.946164 -0.514522  1.23  11.579164 -4.174933  74.850744   \n",
       "3  92.718948 -21.856291 -0.509879  1.24  11.200789 -4.025856  74.231856   \n",
       "4  92.267388 -21.776992 -0.509390  1.24  11.123343 -4.030419  74.254992   \n",
       "\n",
       "        vix  Target  \n",
       "0  0.359786     1.0  \n",
       "1  0.359786     0.0  \n",
       "2  0.353896     1.0  \n",
       "3  0.366412     1.0  \n",
       "4  0.347269     1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(['국고채'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쉼표 제거 및 숫자 형식으로 변환, 날짜 열은 제외\n",
    "for column in df.columns:\n",
    "    if column != '날짜':\n",
    "        df[column] = df[column].apply(lambda x: str(x).replace(',', '') if isinstance(x, str) else x)\n",
    "        df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 칼럼을 datetime 객체로 변환\n",
    "df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "df.set_index('날짜', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처와 타겟을 분리합니다\n",
    "features = df.drop('Target', axis=1)\n",
    "target = df['Target']\n",
    "\n",
    "# 피처 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# LSTM 입력 형식으로 변환 (samples, time steps, features)\n",
    "time_steps = 5  # 이전 5일의 데이터를 사용하여 예측\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(time_steps, len(scaled_features)):\n",
    "    X.append(scaled_features[i-time_steps:i])\n",
    "    y.append(target.values[i])\n",
    "\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7  # 훈련 세트 비율\n",
    "split_index = int(split_ratio * len(X))\n",
    "\n",
    "X_train, y_train = X[:split_index], y[:split_index]\n",
    "X_test, y_test = X[split_index:], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(units=20))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 25ms/step - loss: 0.6877 - accuracy: 0.5371 - val_loss: 0.6918 - val_accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.5515 - val_loss: 0.6916 - val_accuracy: 0.5597\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.5134 - val_loss: 0.6914 - val_accuracy: 0.5391\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6843 - accuracy: 0.5608 - val_loss: 0.6942 - val_accuracy: 0.4815\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6861 - accuracy: 0.5330 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.5505 - val_loss: 0.7017 - val_accuracy: 0.4774\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5629 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.5577 - val_loss: 0.6981 - val_accuracy: 0.4856\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6848 - accuracy: 0.5526 - val_loss: 0.6918 - val_accuracy: 0.5473\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.5701 - val_loss: 0.6909 - val_accuracy: 0.5514\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6837 - accuracy: 0.5691 - val_loss: 0.6936 - val_accuracy: 0.5144\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.5588 - val_loss: 0.6909 - val_accuracy: 0.5062\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.5546 - val_loss: 0.6909 - val_accuracy: 0.5432\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6828 - accuracy: 0.5588 - val_loss: 0.6909 - val_accuracy: 0.5267\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5526 - val_loss: 0.6918 - val_accuracy: 0.5103\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6830 - accuracy: 0.5485 - val_loss: 0.6918 - val_accuracy: 0.5473\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6855 - accuracy: 0.5546 - val_loss: 0.6910 - val_accuracy: 0.5350\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6842 - accuracy: 0.5670 - val_loss: 0.6910 - val_accuracy: 0.5309\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6817 - accuracy: 0.5567 - val_loss: 0.6917 - val_accuracy: 0.5309\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6822 - accuracy: 0.5629 - val_loss: 0.6910 - val_accuracy: 0.5391\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.5454 - val_loss: 0.6975 - val_accuracy: 0.5144\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.5505 - val_loss: 0.6933 - val_accuracy: 0.5144\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6832 - accuracy: 0.5598 - val_loss: 0.6936 - val_accuracy: 0.5144\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6816 - accuracy: 0.5680 - val_loss: 0.6949 - val_accuracy: 0.5144\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5515 - val_loss: 0.6954 - val_accuracy: 0.5144\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.5546 - val_loss: 0.6953 - val_accuracy: 0.5144\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5577 - val_loss: 0.7017 - val_accuracy: 0.5144\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5794 - val_loss: 0.6924 - val_accuracy: 0.5267\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.5608 - val_loss: 0.7014 - val_accuracy: 0.5144\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.5402 - val_loss: 0.6944 - val_accuracy: 0.5062\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6826 - accuracy: 0.5639 - val_loss: 0.6955 - val_accuracy: 0.5144\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6830 - accuracy: 0.5649 - val_loss: 0.7031 - val_accuracy: 0.5144\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6821 - accuracy: 0.5598 - val_loss: 0.7047 - val_accuracy: 0.5144\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.5742 - val_loss: 0.6997 - val_accuracy: 0.5144\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6801 - accuracy: 0.5753 - val_loss: 0.7049 - val_accuracy: 0.5144\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6800 - accuracy: 0.5639 - val_loss: 0.6998 - val_accuracy: 0.5144\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5742 - val_loss: 0.7028 - val_accuracy: 0.5144\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.5619 - val_loss: 0.7042 - val_accuracy: 0.5144\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.5526 - val_loss: 0.7128 - val_accuracy: 0.5144\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6797 - accuracy: 0.5763 - val_loss: 0.7065 - val_accuracy: 0.5144\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5402 - val_loss: 0.7023 - val_accuracy: 0.5144\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6811 - accuracy: 0.5608 - val_loss: 0.7184 - val_accuracy: 0.5144\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.5639 - val_loss: 0.7135 - val_accuracy: 0.5144\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.5495 - val_loss: 0.7110 - val_accuracy: 0.5144\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5722 - val_loss: 0.7163 - val_accuracy: 0.5144\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6785 - accuracy: 0.5629 - val_loss: 0.7049 - val_accuracy: 0.5144\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6858 - accuracy: 0.5680 - val_loss: 0.7068 - val_accuracy: 0.5144\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6815 - accuracy: 0.5598 - val_loss: 0.7047 - val_accuracy: 0.5144\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6781 - accuracy: 0.5557 - val_loss: 0.7157 - val_accuracy: 0.5144\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.5784 - val_loss: 0.7194 - val_accuracy: 0.5144\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6836 - accuracy: 0.5443 - val_loss: 0.6984 - val_accuracy: 0.5144\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5598 - val_loss: 0.7150 - val_accuracy: 0.5144\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.5557 - val_loss: 0.7097 - val_accuracy: 0.5144\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5608 - val_loss: 0.7090 - val_accuracy: 0.5144\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5557 - val_loss: 0.7142 - val_accuracy: 0.5144\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5608 - val_loss: 0.7044 - val_accuracy: 0.5144\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5784 - val_loss: 0.7178 - val_accuracy: 0.5144\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6806 - accuracy: 0.5649 - val_loss: 0.7169 - val_accuracy: 0.5144\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6828 - accuracy: 0.5598 - val_loss: 0.7061 - val_accuracy: 0.5144\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.5649 - val_loss: 0.7138 - val_accuracy: 0.5144\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.5495 - val_loss: 0.7130 - val_accuracy: 0.5144\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5701 - val_loss: 0.7048 - val_accuracy: 0.5144\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5619 - val_loss: 0.7091 - val_accuracy: 0.5144\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6781 - accuracy: 0.5670 - val_loss: 0.7096 - val_accuracy: 0.5144\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5660 - val_loss: 0.7104 - val_accuracy: 0.5144\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.5588 - val_loss: 0.7147 - val_accuracy: 0.5144\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6781 - accuracy: 0.5722 - val_loss: 0.7168 - val_accuracy: 0.5144\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.5732 - val_loss: 0.7234 - val_accuracy: 0.5144\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.5711 - val_loss: 0.7391 - val_accuracy: 0.5144\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.5639 - val_loss: 0.7174 - val_accuracy: 0.5144\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6770 - accuracy: 0.5732 - val_loss: 0.7319 - val_accuracy: 0.5144\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.5588 - val_loss: 0.7223 - val_accuracy: 0.5144\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6771 - accuracy: 0.5670 - val_loss: 0.7448 - val_accuracy: 0.5144\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5794 - val_loss: 0.7323 - val_accuracy: 0.5144\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6767 - accuracy: 0.5691 - val_loss: 0.7393 - val_accuracy: 0.5144\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.5680 - val_loss: 0.7368 - val_accuracy: 0.5144\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5660 - val_loss: 0.7239 - val_accuracy: 0.5144\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5753 - val_loss: 0.7343 - val_accuracy: 0.5144\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6789 - accuracy: 0.5670 - val_loss: 0.7190 - val_accuracy: 0.5144\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5691 - val_loss: 0.7079 - val_accuracy: 0.5144\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.5804 - val_loss: 0.7265 - val_accuracy: 0.5144\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.5691 - val_loss: 0.7204 - val_accuracy: 0.5144\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6766 - accuracy: 0.5619 - val_loss: 0.7254 - val_accuracy: 0.5144\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6747 - accuracy: 0.5608 - val_loss: 0.7285 - val_accuracy: 0.5144\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5701 - val_loss: 0.7456 - val_accuracy: 0.5144\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5680 - val_loss: 0.7180 - val_accuracy: 0.5144\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.5639 - val_loss: 0.7335 - val_accuracy: 0.5144\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6775 - accuracy: 0.5670 - val_loss: 0.7175 - val_accuracy: 0.5144\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.5505 - val_loss: 0.7324 - val_accuracy: 0.5144\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6783 - accuracy: 0.5691 - val_loss: 0.7245 - val_accuracy: 0.5144\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.5577 - val_loss: 0.7394 - val_accuracy: 0.5144\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6782 - accuracy: 0.5660 - val_loss: 0.7220 - val_accuracy: 0.5144\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6774 - accuracy: 0.5701 - val_loss: 0.7292 - val_accuracy: 0.5144\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.5722 - val_loss: 0.7090 - val_accuracy: 0.5144\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6762 - accuracy: 0.5680 - val_loss: 0.7247 - val_accuracy: 0.5144\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6749 - accuracy: 0.5649 - val_loss: 0.7088 - val_accuracy: 0.5144\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5619 - val_loss: 0.7363 - val_accuracy: 0.5144\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6776 - accuracy: 0.5588 - val_loss: 0.7193 - val_accuracy: 0.5144\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5619 - val_loss: 0.7170 - val_accuracy: 0.5144\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.5701 - val_loss: 0.7220 - val_accuracy: 0.5144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d4d615e8d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)  # 이진 분류 문제이므로 0.5를 기준으로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.508637236084453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
